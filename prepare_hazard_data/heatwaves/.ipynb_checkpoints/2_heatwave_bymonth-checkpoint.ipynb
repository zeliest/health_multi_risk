{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ca54b3-e926-4912-baca-0de1b870f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heatwave_indices\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f762a51b-1a22-4d87-a19c-5c36d60cfb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_YEAR = 2023\n",
    "\n",
    "TEMPERATURES_FOLDER = Path('/nfs/n2o/wcr/szelie/era5/era5_0.25deg/daily_temperature_summary')\n",
    "CLIMATOLOGY_QUANTILES = Path('/nfs/n2o/wcr/szelie/era5/era5_0.25deg/quantiles')\n",
    "\n",
    "\n",
    "INTERMEDIATE_RESULTS_FOLDER = Path('/nfs/n2o/wcr/szelie/lancet/heatwaves/results_2024/heatwaves_monthly')\n",
    "INTERMEDIATE_RESULTS_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "assert INTERMEDIATE_RESULTS_FOLDER.is_dir()\n",
    "\n",
    "\n",
    "# Apply heatwave index function to selected vars using selected threshold days\n",
    "\n",
    "def ds_for_year(year):\n",
    "    temperature_files = []\n",
    "    # Filter temperature files based on the year in the filename\n",
    "    for file in TEMPERATURES_FOLDER.glob('*'):\n",
    "        if str(year) in file.name:\n",
    "            temperature_files.append(file)\n",
    "    print(temperature_files)\n",
    "    ds = xr.open_mfdataset(temperature_files)\n",
    "    print(ds)\n",
    "    #ds = ds.drop('time_bnds')\n",
    "    ds = ds.transpose('time', 'latitude', 'longitude')\n",
    "    ds =ds.rename({\"t_min\": \"tmin\", \"t_max\":\"tmax\", \"t_mean\":\"tmean\"})\n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f93a74-205c-4cac-86e6-e3fbf778da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_func_for_file(func, year, t_thresholds, t_var_names, days_threshold=2):\n",
    "    ds = ds_for_year(year)\n",
    "    \n",
    "    datasets_year = [ds[name] for name in t_var_names]\n",
    "    result = func(datasets_year, t_thresholds, days_threshold)\n",
    "    \n",
    "    # Add a year dimension matching the input file\n",
    "    result = result.expand_dims(dim={'year': [year]})\n",
    "    return year, result\n",
    "\n",
    "\n",
    "def apply_func_and_save(func, year, output_folder, t_thresholds,  t_var_names=['tmin', 'tmax'], \n",
    "                        days_threshold=2, overwrite=False,\n",
    "                        filename_pattern='indicator_{year}.nc'\n",
    "                       ):\n",
    "    output_file = output_folder / filename_pattern.format(year=year)\n",
    "    if output_file.exists() is False and overwrite is False:\n",
    "        year, result = apply_func_for_file(func, year, t_thresholds, t_var_names=t_var_names, days_threshold=days_threshold)\n",
    "        result.to_netcdf(output_file)\n",
    "        return f'Created {output_file}'\n",
    "    else:\n",
    "        return f'Skipped {output_file}, already exists'\n",
    "\n",
    "\n",
    "# # Calculate heatwave occurances\n",
    "\n",
    "def main(indicator, year):\n",
    "    if indicator == 'heatwave_counts':\n",
    "        func = heatwave_indices.heatwaves_counts_multi_threshold\n",
    "    elif indicator == 'heatwave_days':\n",
    "        func = heatwave_indices.heatwaves_days_multi_threshold\n",
    "    else:\n",
    "        raise RuntimeError('Wrong indicator name')\n",
    "\n",
    "    out_folder = INTERMEDIATE_RESULTS_FOLDER / indicator\n",
    "    out_folder.mkdir(exist_ok=True)\n",
    "    \n",
    "    quantiles_files = list(CLIMATOLOGY_QUANTILES.rglob('*.nc'))\n",
    "    print(quantiles_files)\n",
    "\n",
    "    # ## Load ERA5 reference temperature quantiles\n",
    "    # Load both the tmin and tmax quatiles and place in a list\n",
    "    QUANTILE = 0.95\n",
    "\n",
    "    t_quantiles = xr.open_mfdataset(quantiles_files, compat='override')\n",
    "    # Need to use tolerance/nearest b/c of floating point drift (0.95 != 0.95)\n",
    "    t_quantiles = t_quantiles.rename({\"t_min\":\"tmin\", \"t_max\":\"tmax\", \"t_mean\":\"tmean\"})\n",
    "    t_min_threshold = t_quantiles.tmin.sel(quantile=QUANTILE, drop=True, tolerance=0.001, method='nearest')\n",
    "    t_max_threshold = t_quantiles.tmax.sel(quantile=QUANTILE, drop=True, tolerance=0.001, method='nearest')\n",
    "\n",
    "    t_thresholds = [t_min_threshold, t_max_threshold]\n",
    "\n",
    "    return apply_func_and_save(func, year, out_folder, t_thresholds, t_var_names=['tmin', 'tmax'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551af049-ba32-48fc-9688-409ca3def29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "def heatwaves_days_multi_threshold_monthly(datasets_year, thresholds, days_threshold: int = 2):\n",
    "    \"\"\"\n",
    "    Accepts data as a (time, lat, lon) shaped boolean array.\n",
    "    Iterates through the array in the time dimension comparing the current\n",
    "    time slice to the previous one. For each cell, determines whether the\n",
    "    cell is True (i.e., is over the heatwave thresholds) and whether this is\n",
    "    the start, continuation, or end of a sequence of heatwave conditions.\n",
    "    Accumulates the number of days and counts the total lengths.\n",
    "    \"\"\"\n",
    "    # Initialize empty arrays to accumulate results\n",
    "    out_shape: tuple = datasets_year[0].shape[1:]\n",
    "    days = np.zeros(out_shape, dtype=np.int32)\n",
    "    \n",
    "    for data_year in datasets_year:\n",
    "        # Fill NaN values with a sentinel value (-9999)\n",
    "        data_year = data_year.fillna(-9999)\n",
    "        \n",
    "        # Initialize arrays for this year's calculations\n",
    "        threshold_exceeded = data_year > thresholds[0]\n",
    "        accumulator = np.zeros(out_shape, dtype=np.int32)\n",
    "        last_slice = threshold_exceeded[0, :, :]\n",
    "        curr_slice = threshold_exceeded[0, :, :]\n",
    "        hw_ends = np.zeros(out_shape, dtype=bool)\n",
    "        mask = np.zeros(out_shape, dtype=bool)\n",
    "        \n",
    "        for i in range(1, data_year.shape[0]):\n",
    "            last_slice = threshold_exceeded[i - 1, :, :]\n",
    "            curr_slice = threshold_exceeded[i, :, :]\n",
    "\n",
    "            # Add to the sequence length counter at all positions\n",
    "            # above threshold at the previous time step using boolean indexing\n",
    "            accumulator[last_slice] += 1\n",
    "\n",
    "            # End of sequence is where prev is true and current is false\n",
    "            # Perform operations using Dask arrays\n",
    "            last_slice = da.from_array(last_slice, chunks=last_slice.shape)\n",
    "            curr_slice = da.from_array(curr_slice, chunks=curr_slice.shape)\n",
    "            hw_ends = da.from_array(hw_ends, chunks=hw_ends.shape)\n",
    "            mask = da.from_array(mask, chunks=mask.shape)\n",
    "\n",
    "            # Perform operations using Dask arrays\n",
    "            da.logical_and(last_slice, da.logical_not(curr_slice), out=hw_ends)\n",
    "            da.logical_and(hw_ends, (accumulator > days_threshold), out=mask)\n",
    "\n",
    "            # Convert Dask arrays back to Numpy arrays if needed\n",
    "            hw_ends = hw_ends.compute()\n",
    "            mask = mask.compute()\n",
    "            # np.logical_and(last_slice, np.logical_not(curr_slice), out=hw_ends)\n",
    "            # np.logical_and(hw_ends, (accumulator > days_threshold), out=mask)\n",
    "\n",
    "            # Add the length of the accumulator where the sequences are ending and are > 3\n",
    "            days[mask] += accumulator[mask]\n",
    "            # Reset the accumulator where the current slice is empty\n",
    "            accumulator[np.logical_not(curr_slice)] = 0\n",
    "        \n",
    "        # Finally, 'close' the heatwaves that are ongoing at the end of the year\n",
    "        da.logical_and(curr_slice, (accumulator > days_threshold), out=mask)\n",
    "\n",
    "        # Add the length of the accumulator where the sequences are ending and are > 3\n",
    "        days[mask] += accumulator[mask]\n",
    "\n",
    "    # Convert the numpy array to a DataArray, keeping the 'time' dimension\n",
    "    time_dim = datasets_year[0].time.values\n",
    "    days_da = xr.DataArray(\n",
    "        days,\n",
    "        coords=[datasets_year[0].latitude.values, datasets_year[0].longitude.values, time_dim],\n",
    "        dims=['latitude', 'longitude', 'time'],\n",
    "        name='heatwaves_days'\n",
    "    )\n",
    "\n",
    "    return days_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d31678e-8f81-451a-8a07-4b65c3916b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--year YEAR] indicator\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('indicator')\n",
    "parser.add_argument('--year', type=int)\n",
    "args = parser.parse_args()\n",
    "if not args.year:\n",
    "    import os\n",
    "    year = int(os.getenv('SLURM_ARRAY_TASK_ID'))\n",
    "else:\n",
    "    year = args.year\n",
    "\n",
    "if year is None:\n",
    "    raise RuntimeError('Must supply year as arg or env var')\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "print(now.isoformat(), f' processing {args.indicator} {year}')\n",
    "res = main(args.indicator, year)\n",
    "now = datetime.now()\n",
    "print(now.isoformat(), f' {args.indicator} {year}: {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c8d1c4-19ad-4135-bb6a-7775be9e7705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year extracted from filename: 2000\n"
     ]
    }
   ],
   "source": [
    "def year_from_filename(name):\n",
    "    # Extract the year from the filename\n",
    "    parts = name.split('_')\n",
    "    if len(parts) >= 1:\n",
    "        try:\n",
    "            year = int(parts[0])\n",
    "            return year\n",
    "        except ValueError:\n",
    "            pass\n",
    "    # If extraction fails, return None or raise an exception, depending on your preference\n",
    "    return None\n",
    "\n",
    "# Example usage:\n",
    "filename = \"2000_temperature_summary.nc\"\n",
    "year = year_from_filename(filename)\n",
    "if year is not None:\n",
    "    print(f\"Year extracted from filename: {year}\")\n",
    "else:\n",
    "    print(\"Failed to extract the year from the filename.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1679b14-2cf5-46ba-8ff7-7c366719174c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot specify both coords='different' and compat='override'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m2000\u001b[39m,\u001b[38;5;241m2020\u001b[39m):\n\u001b[0;32m---> 57\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheatwave_days\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(indicator, year)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Load ERA5 reference temperature quantiles\u001b[39;00m\n\u001b[1;32m     39\u001b[0m QUANTILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.95\u001b[39m\n\u001b[0;32m---> 40\u001b[0m t_quantiles \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantiles_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverride\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m t_quantiles \u001b[38;5;241m=\u001b[39m t_quantiles\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_min\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmean\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     42\u001b[0m t_min_threshold \u001b[38;5;241m=\u001b[39m t_quantiles\u001b[38;5;241m.\u001b[39mtmin\u001b[38;5;241m.\u001b[39msel(quantile\u001b[38;5;241m=\u001b[39mQUANTILE, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/backends/api.py:936\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m     combined \u001b[38;5;241m=\u001b[39m _nested_combine(\n\u001b[1;32m    924\u001b[0m         datasets,\n\u001b[1;32m    925\u001b[0m         concat_dims\u001b[38;5;241m=\u001b[39mconcat_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    931\u001b[0m         combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    932\u001b[0m     )\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m combine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby_coords\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;66;03m# Redo ordering from coordinates, ignoring how they were ordered\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;66;03m# previously\u001b[39;00m\n\u001b[0;32m--> 936\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_by_coords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    946\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is an invalid option for the keyword argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ``combine``\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(combine)\n\u001b[1;32m    948\u001b[0m     )\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/core/combine.py:975\u001b[0m, in \u001b[0;36mcombine_by_coords\u001b[0;34m(data_objects, compat, data_vars, coords, fill_value, join, combine_attrs, datasets)\u001b[0m\n\u001b[1;32m    973\u001b[0m     concatenated_grouped_by_data_vars \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mvars\u001b[39m, datasets_with_same_vars \u001b[38;5;129;01min\u001b[39;00m grouped_by_vars:\n\u001b[0;32m--> 975\u001b[0m         concatenated \u001b[38;5;241m=\u001b[39m \u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m         concatenated_grouped_by_data_vars\u001b[38;5;241m.\u001b[39mappend(concatenated)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m    987\u001b[0m     concatenated_grouped_by_data_vars,\n\u001b[1;32m    988\u001b[0m     compat\u001b[38;5;241m=\u001b[39mcompat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    991\u001b[0m     combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    992\u001b[0m )\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/core/combine.py:637\u001b[0m, in \u001b[0;36m_combine_single_variable_hypercube\u001b[0;34m(datasets, fill_value, data_vars, coords, compat, join, combine_attrs)\u001b[0m\n\u001b[1;32m    634\u001b[0m     _check_dimension_depth_tile_ids(combined_ids)\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# Concatenate along all of concat_dims one by one to create single ds\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m concatenated \u001b[38;5;241m=\u001b[39m \u001b[43m_combine_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombined_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcat_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# Check the overall coordinates are monotonically increasing\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m concat_dims:\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/core/combine.py:234\u001b[0m, in \u001b[0;36m_combine_nd\u001b[0;34m(combined_ids, concat_dims, data_vars, coords, compat, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Each iteration of this loop reduces the length of the tile_ids tuples\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# by one. It always combines along the first dimension, removing the first\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# element of the tuple\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m concat_dim \u001b[38;5;129;01min\u001b[39;00m concat_dims:\n\u001b[0;32m--> 234\u001b[0m     combined_ids \u001b[38;5;241m=\u001b[39m \u001b[43m_combine_all_along_first_dim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombined_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m (combined_ds,) \u001b[38;5;241m=\u001b[39m combined_ids\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m combined_ds\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/core/combine.py:270\u001b[0m, in \u001b[0;36m_combine_all_along_first_dim\u001b[0;34m(combined_ids, dim, data_vars, coords, compat, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     combined_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28msorted\u001b[39m(group))\n\u001b[1;32m    269\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m combined_ids\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m--> 270\u001b[0m     new_combined_ids[new_id] \u001b[38;5;241m=\u001b[39m \u001b[43m_combine_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine_attrs\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_combined_ids\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/core/combine.py:293\u001b[0m, in \u001b[0;36m_combine_1d\u001b[0;34m(datasets, concat_dim, compat, data_vars, coords, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 293\u001b[0m         combined \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencountered unexpected variable\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/core/concat.py:238\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only concatenate xarray Dataset and DataArray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(first_obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m     )\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine_attrs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/core/concat.py:459\u001b[0m, in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m [ds\u001b[38;5;241m.\u001b[39mexpand_dims(dim) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# determine which variables to concatenate\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m concat_over, equals, concat_dim_lengths \u001b[38;5;241m=\u001b[39m \u001b[43m_calc_concat_over\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# determine which variables to merge, and then merge them according to compat\u001b[39;00m\n\u001b[1;32m    464\u001b[0m variables_to_merge \u001b[38;5;241m=\u001b[39m (coord_names \u001b[38;5;241m|\u001b[39m data_names) \u001b[38;5;241m-\u001b[39m concat_over \u001b[38;5;241m-\u001b[39m dim_names\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/core/concat.py:379\u001b[0m, in \u001b[0;36m_calc_concat_over\u001b[0;34m(datasets, dim, dim_names, data_vars, coords, compat)\u001b[0m\n\u001b[1;32m    376\u001b[0m         concat_over\u001b[38;5;241m.\u001b[39mupdate(opt)\n\u001b[1;32m    378\u001b[0m process_subset_opt(data_vars, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_vars\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 379\u001b[0m \u001b[43mprocess_subset_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat_over, equals, concat_dim_lengths\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64/python3.10/site-packages/xarray/core/concat.py:296\u001b[0m, in \u001b[0;36m_calc_concat_over.<locals>.process_subset_opt\u001b[0;34m(opt, subset)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compat \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    297\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify both \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and compat=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m         )\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# all nonindexes that are not the same in each dataset\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(datasets[\u001b[38;5;241m0\u001b[39m], subset):\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot specify both coords='different' and compat='override'."
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "def apply_func_for_month(func, year, month, t_thresholds, t_var_names, days_threshold=2):\n",
    "    ds = ds_for_year(year)  # Use the ds_for_year function and adjust the time coordinate\n",
    "    ds = ds.sel(time=f\"{year}-{month:02}\")  # Select data for the specific month\n",
    "    \n",
    "    datasets_month = [ds[name] for name in t_var_names]\n",
    "    result = func(datasets_month, t_thresholds, days_threshold)\n",
    "    \n",
    "    return year, month, result\n",
    "\n",
    "def apply_func_and_combine(func, year, t_thresholds, t_var_names=['tmin', 'tmax'], days_threshold=2):\n",
    "    combined_results = []\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        year, month, result = apply_func_for_month(func, year, month, t_thresholds, t_var_names, days_threshold)\n",
    "        combined_results.append(result)\n",
    "\n",
    "    combined_result = xr.concat(combined_results, dim='month')\n",
    "    combined_result = combined_result.assign_coords(month=np.arange(1, 13))  # Assign month coordinate\n",
    "\n",
    "    return combined_result\n",
    "\n",
    "def main(indicator, year):\n",
    "    if indicator == 'heatwave_counts':\n",
    "        func = heatwave_indices.heatwaves_counts_multi_threshold\n",
    "    elif indicator == 'heatwave_days':\n",
    "        func = heatwave_indices.heatwaves_days_multi_threshold\n",
    "    else:\n",
    "        raise RuntimeError('Wrong indicator name')\n",
    "\n",
    "    out_folder = INTERMEDIATE_RESULTS_FOLDER / indicator\n",
    "    out_folder.mkdir(exist_ok=True)\n",
    "    \n",
    "    quantiles_files = list(CLIMATOLOGY_QUANTILES.rglob('*.nc'))\n",
    "\n",
    "    # Load ERA5 reference temperature quantiles\n",
    "    QUANTILE = 0.95\n",
    "    t_quantiles = xr.open_mfdataset(quantiles_files)\n",
    "    t_quantiles = t_quantiles.rename({\"t_min\": \"tmin\", \"t_max\": \"tmax\", \"t_mean\": \"tmean\"})\n",
    "    t_min_threshold = t_quantiles.tmin.sel(quantile=QUANTILE, drop=True)\n",
    "    t_max_threshold = t_quantiles.tmax.sel(quantile=QUANTILE, drop=True)\n",
    "    t_thresholds = [t_min_threshold, t_max_threshold]\n",
    "\n",
    "    # Call the function to apply and combine the results for each month\n",
    "    combined_result = apply_func_and_combine(func, year, t_thresholds, t_var_names=['tmin', 'tmax'])\n",
    "\n",
    "    # Now you have a single dataset containing results for all months of the year\n",
    "    # You can do further processing or save this dataset as needed\n",
    "    output_file = INTERMEDIATE_RESULTS_FOLDER / f'indicator_{year}.nc'\n",
    "    combined_result.to_netcdf(output_file)\n",
    "    return f'Created {output_file}'\n",
    "\n",
    "# Example usage:\n",
    "for year in np.arange(2000,2020):\n",
    "    main(\"heatwave_days\", year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e22eb-bd6d-4df8-a87f-b2fd8632f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(\"/nfs/n2o/wcr/szelie/era5/era5_0.5deg/heatwave_days_era5land/indicator_2020.nc\").heatwaves_days.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climada_venv",
   "language": "python",
   "name": "climada_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
